{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net1, net2, device):\n",
    "#     if device is None and isinstance(net1, torch.nn.Module):\n",
    "#         # 如果没指定device就使用net的device\n",
    "#         device = list(net1.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds1 = net1(X.to(device))\n",
    "            preds2 = net2(X.to(device))\n",
    "            preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            \n",
    "            acc_sum += (torch.from_numpy(preds).to(device).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            \n",
    "#             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "#             net.train() # 改回训练模式\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy2(data_iter, net, device):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "           \n",
    "            net.eval() # 评估模式, 这会关闭dropout\n",
    "            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            net.train() # 改回训练模式\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135104578858112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy2(test_iter_152, resnet152, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import time\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import os\n",
    "# from scipy.special import softmax\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "# import d2lzh_pytorch as d2l\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face_18(batch_size):\n",
    "    \n",
    "    transform = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.Grayscale(num_output_channels=3), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        #torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.Resize([224, 224]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225])\n",
    "\n",
    "        ])\n",
    "    \n",
    "    test_imgs = torchvision.datasets.ImageFolder('dataset/test', transform=transform)\n",
    "    test_iter = torch.utils.data.DataLoader(test_imgs, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    \n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face_50(batch_size):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_imgs = torchvision.datasets.ImageFolder('dataset/test', transform=transform)\n",
    "\n",
    "    test_iter = torch.utils.data.DataLoader(test_imgs, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face_152(batch_size):\n",
    "    \n",
    "    transform = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    test_imgs = torchvision.datasets.ImageFolder('dataset/test', transform=transform)\n",
    "    test_iter = torch.utils.data.DataLoader(test_imgs, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    \n",
    "    return test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torch.load('./model_resnet18-925.pkl').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torch.load('./resnet50(923).pkl').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152 = torch.load('./work/resnet152.pkl').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_iter_18 = load_data_face_18(batch_size) \n",
    "test_iter_50 = load_data_face_50(batch_size)\n",
    "test_iter_152 = load_data_face_152(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_two(data_iter_18, data_iter_50, net1, net2, device):\n",
    "#     if device is None and isinstance(net1, torch.nn.Module):\n",
    "#         # 如果没指定device就使用net的device\n",
    "#         device = list(net1.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    preds_18 = []\n",
    "#     preds_50 = []\n",
    "    with torch.no_grad():\n",
    "        for X1, y1 in data_iter_18:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds18 = net1(X1.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "#             preds18 = softmax(preds18.cpu().numpy())\n",
    "            preds18 = softmax(preds18,dim=1)\n",
    "#             preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            preds_18.append(preds18)\n",
    "      \n",
    "        m = 0\n",
    "        for X2, y2 in data_iter_50:\n",
    "            preds50 = net2(X2.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds50 = softmax(preds50,dim=1)\n",
    "#             preds50 = softmax(preds50.cpu().numpy())\n",
    "            preds =2/5 * preds50 + 2/5 * preds_18[m]\n",
    "#             preds = 2/5 * preds152 + 1/5 * preds_18[m] + 2/5 * preds_50[m]\n",
    "            acc_sum += (preds.argmax(dim=1) == y2.to(device)).float().sum().cpu().item()\n",
    "            m += 1\n",
    "#             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "#             net.train() # 改回训练模式\n",
    "            n += y2.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366873940079141"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy_two(test_iter_50, test_iter_152, resnet50, resnet152, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter_18, data_iter_50, data_iter_152, net1, net2, net3, device):\n",
    "#     if device is None and isinstance(net1, torch.nn.Module):\n",
    "#         # 如果没指定device就使用net的device\n",
    "#         device = list(net1.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    net3.eval()\n",
    "    preds_18 = []\n",
    "    preds_50 = []\n",
    "    with torch.no_grad():\n",
    "        for X1, y1 in data_iter_18:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds18 = net1(X1.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds18 = softmax(preds18,dim=1)\n",
    "#             preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            preds_18.append(preds18)\n",
    "        for X2, y2 in data_iter_50:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds50 = net2(X2.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds50 = softmax(preds50,dim=1)\n",
    "#             preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            preds_50.append(preds50)\n",
    "        m = 0\n",
    "        for X3, y3 in data_iter_152:\n",
    "            preds152 = net3(X3.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds152 = softmax(preds152,dim=1)\n",
    "#             preds =1/5 * preds152 + 2/5 * preds_50[m]\n",
    "            preds = 3/8 * preds152 + 0 * preds_18[m] + 3/8 * preds_50[m]\n",
    "            acc_sum += (preds.argmax(dim=1) == y3.to(device)).float().sum().cpu().item()\n",
    "            m += 1\n",
    "#             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "#             net.train() # 改回训练模式\n",
    "            n += y3.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389485585076315\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter_18, test_iter_50, test_iter_152, resnet18, resnet50, resnet152, device)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version   \n",
      "---------------------- ----------\n",
      "absl-py                0.7.0     \n",
      "alembic                0.9.9     \n",
      "asn1crypto             0.24.0    \n",
      "astor                  0.7.1     \n",
      "async-generator        1.10      \n",
      "attrs                  18.2.0    \n",
      "backcall               0.1.0     \n",
      "beautifulsoup4         4.6.3     \n",
      "bleach                 1.5.0     \n",
      "bokeh                  0.13.0    \n",
      "certifi                2018.11.29\n",
      "cffi                   1.11.5    \n",
      "chardet                3.0.4     \n",
      "cloudpickle            0.5.6     \n",
      "cnn-finetune           0.3       \n",
      "conda                  4.6.2     \n",
      "cryptography           2.5       \n",
      "cycler                 0.10.0    \n",
      "Cython                 0.28.5    \n",
      "cytoolz                0.9.0.1   \n",
      "d2lzh                  1.0.0     \n",
      "dask                   1.1.1     \n",
      "decorator              4.3.0     \n",
      "dill                   0.2.9     \n",
      "entrypoints            0.3       \n",
      "fastcache              1.0.2     \n",
      "gast                   0.2.2     \n",
      "gluonbook              0.8.10    \n",
      "gmpy2                  2.0.8     \n",
      "google-pasta           0.2.0     \n",
      "graphviz               0.8.4     \n",
      "grpcio                 1.18.0    \n",
      "h5py                   2.7.1     \n",
      "html5lib               0.9999999 \n",
      "idna                   2.8       \n",
      "imageio                2.4.1     \n",
      "ipykernel              5.1.0     \n",
      "ipython                7.2.0     \n",
      "ipython-genutils       0.2.0     \n",
      "ipywidgets             7.4.2     \n",
      "jedi                   0.13.2    \n",
      "Jinja2                 2.10      \n",
      "jsonschema             3.0.0a3   \n",
      "jupyter                1.0.0     \n",
      "jupyter-client         5.2.4     \n",
      "jupyter-console        6.0.0     \n",
      "jupyter-core           4.4.0     \n",
      "jupyter-tensorboard    0.2.0     \n",
      "jupyterhub             0.9.4     \n",
      "jupyterlab             0.35.4    \n",
      "jupyterlab-server      0.2.0     \n",
      "Keras                  2.2.4     \n",
      "Keras-Applications     1.0.8     \n",
      "Keras-Preprocessing    1.1.2     \n",
      "kiwisolver             1.0.1     \n",
      "llvmlite               0.23.0    \n",
      "Mako                   1.0.7     \n",
      "Markdown               3.0.1     \n",
      "MarkupSafe             1.1.0     \n",
      "matplotlib             2.2.3     \n",
      "mistune                0.8.4     \n",
      "mpmath                 1.1.0     \n",
      "munch                  2.5.0     \n",
      "mxnet-cu90             1.3.1     \n",
      "nbconvert              5.3.1     \n",
      "nbformat               4.4.0     \n",
      "networkx               2.2       \n",
      "notebook               5.7.2     \n",
      "numba                  0.38.1    \n",
      "numexpr                2.6.9     \n",
      "numpy                  1.14.6    \n",
      "olefile                0.46      \n",
      "opt-einsum             3.2.1     \n",
      "packaging              19.0      \n",
      "pamela                 0.3.0     \n",
      "pandas                 0.23.4    \n",
      "pandocfilters          1.4.2     \n",
      "parso                  0.3.1     \n",
      "patsy                  0.5.1     \n",
      "pexpect                4.6.0     \n",
      "pickleshare            0.7.5     \n",
      "Pillow                 5.4.1     \n",
      "pip                    19.0.1    \n",
      "pretrainedmodels       0.7.4     \n",
      "prometheus-client      0.5.0     \n",
      "prompt-toolkit         2.0.7     \n",
      "protobuf               3.6.1     \n",
      "ptyprocess             0.6.0     \n",
      "pycosat                0.6.3     \n",
      "pycparser              2.19      \n",
      "pycurl                 7.43.0.2  \n",
      "Pygments               2.3.1     \n",
      "pyOpenSSL              19.0.0    \n",
      "pyparsing              2.3.1     \n",
      "pyrsistent             0.14.9    \n",
      "PySocks                1.6.8     \n",
      "python-dateutil        2.7.5     \n",
      "python-editor          1.0.3     \n",
      "python-oauth2          1.0.1     \n",
      "pytz                   2018.9    \n",
      "PyWavelets             1.0.1     \n",
      "PyYAML                 3.13      \n",
      "pyzmq                  17.1.2    \n",
      "qtconsole              4.4.3     \n",
      "requests               2.21.0    \n",
      "rpy2                   2.9.4     \n",
      "ruamel-yaml            0.15.71   \n",
      "scikit-image           0.14.2    \n",
      "scikit-learn           0.20.2    \n",
      "scipy                  1.4.1     \n",
      "seaborn                0.9.0     \n",
      "Send2Trash             1.5.0     \n",
      "setuptools             46.3.0    \n",
      "six                    1.12.0    \n",
      "SQLAlchemy             1.2.17    \n",
      "statsmodels            0.9.0     \n",
      "sympy                  1.1.1     \n",
      "tensorboard            1.12.2    \n",
      "tensorflow-estimator   1.15.1    \n",
      "tensorflow-gpu         1.12.0    \n",
      "tensorflow-tensorboard 1.5.1     \n",
      "termcolor              1.1.0     \n",
      "terminado              0.8.1     \n",
      "testpath               0.4.2     \n",
      "toolz                  0.9.0     \n",
      "torch                  1.0.0     \n",
      "torchvision            0.2.1     \n",
      "tornado                5.1.1     \n",
      "tqdm                   4.59.0    \n",
      "traitlets              4.3.2     \n",
      "tzlocal                1.5.1     \n",
      "urllib3                1.24.1    \n",
      "vincent                0.4.4     \n",
      "wcwidth                0.1.7     \n",
      "webencodings           0.5.1     \n",
      "Werkzeug               0.14.1    \n",
      "wheel                  0.32.3    \n",
      "widgetsnbextension     3.4.2     \n",
      "wrapt                  1.12.1    \n",
      "xlrd                   1.2.0     \n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
