{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net1, net2, device):\n",
    "#     if device is None and isinstance(net1, torch.nn.Module):\n",
    "#         # 如果没指定device就使用net的device\n",
    "#         device = list(net1.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds1 = net1(X.to(device))\n",
    "            preds2 = net2(X.to(device))\n",
    "            preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            \n",
    "            acc_sum += (torch.from_numpy(preds).to(device).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            \n",
    "#             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "#             net.train() # 改回训练模式\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy2(data_iter, net, device):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "           \n",
    "            net.eval() # 评估模式, 这会关闭dropout\n",
    "            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "            net.train() # 改回训练模式\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9180327868852459"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy2(test_iter, resnet50, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import time\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "# import d2lzh_pytorch as d2l\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face_50(batch_size):\n",
    "    transform1 = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(0),\n",
    "        torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    transform2 = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(1),\n",
    "        torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_imgs1 = torchvision.datasets.ImageFolder('dataset/test', transform=transform1)\n",
    "    test_imgs2 = torchvision.datasets.ImageFolder('dataset/test', transform=transform2)\n",
    "#     train_iter = torch.utils.data.DataLoader(train_imgs, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter1 = torch.utils.data.DataLoader(test_imgs1, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_iter2 = torch.utils.data.DataLoader(test_imgs2, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return test_iter1,test_iter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face_18(batch_size):\n",
    "    transform1 = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(0),\n",
    "#         torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.Resize([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    transform2 = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(1),\n",
    "#         torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.Resize([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_imgs1 = torchvision.datasets.ImageFolder('dataset/test', transform=transform1)\n",
    "    test_imgs2 = torchvision.datasets.ImageFolder('dataset/test', transform=transform2)\n",
    "\n",
    "    test_iter1 = torch.utils.data.DataLoader(test_imgs1, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_iter2 = torch.utils.data.DataLoader(test_imgs2, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return test_iter1, test_iter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torch.load('./resnet18.pkl').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torch.load('./resnet50918.pkl').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_iter_501, test_iter_502 = load_data_face_50(batch_size)\n",
    "# test_iter_181, test_iter_182 = load_data_face_18(batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_accuracy(data_iter_18, data_iter_50, net1, net2, device):\n",
    "# #     if device is None and isinstance(net1, torch.nn.Module):\n",
    "# #         # 如果没指定device就使用net的device\n",
    "# #         device = list(net1.parameters())[0].device \n",
    "#     acc_sum, n = 0.0, 0\n",
    "#     net1.eval()\n",
    "#     net2.eval()\n",
    "# #     preds_18 = []\n",
    "# #     preds_50 = []\n",
    "#     with torch.no_grad():\n",
    "#         for X1,  X2 in enumerate(data_iter_18, data_iter_50):\n",
    "#             for x, y in X1:\n",
    "#                 print(x.shape)\n",
    "# #             net1.eval() # 评估模式, 这会关闭dropout\n",
    "#             preds18 = net1(X1.to(device))\n",
    "#             preds50 = net2(X2.to(device))\n",
    "# #             preds18 = softmax(preds_18.cpu().numpy())\n",
    "#             preds = 0.5 * softmax(preds18.cpu().numpy()) + 0.5 * softmax(preds50.cpu().numpy()) \n",
    "# #             preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "#             acc_sum += (torch.from_numpy(preds).to(device).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "# #             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "# #             net.train() # 改回训练模式\n",
    "#             n += y1.shape[0]\n",
    "#     return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter_181, data_iter_182, net1, net2, device):\n",
    "#     if device is None and isinstance(net1, torch.nn.Module):\n",
    "#         # 如果没指定device就使用net的device\n",
    "#         device = list(net1.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    preds_18 = []\n",
    "#     preds_50 = []\n",
    "    with torch.no_grad():\n",
    "        for X1, y1 in data_iter_181:\n",
    "#             net1.eval() # 评估模式, 这会关闭dropout\n",
    "            preds18 = net1(X1.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds18 = softmax(preds18.cpu().numpy())\n",
    "#             preds = 0 * softmax(preds1.cpu().numpy()) + 1 * softmax(preds2.cpu().numpy())\n",
    "            preds_18.append(preds18)\n",
    "        m = 0\n",
    "        for X2, y2 in data_iter_182:\n",
    "            preds50 = net1(X2.to(device))\n",
    "#             preds2 = net2(X.to(device))\n",
    "            preds50 = softmax(preds50.cpu().numpy())\n",
    "            preds = 0.5 * preds50 + 0.5 * preds_18[m]\n",
    "            acc_sum += (torch.from_numpy(preds).to(device).argmax(dim=1) == y2.to(device)).float().sum().cpu().item()\n",
    "            m += 1\n",
    "#             acc_sum += (net1(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "#             net.train() # 改回训练模式\n",
    "            n += y2.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_accuracy(test_iter_501, test_iter_502, resnet50, resnet50, device)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
