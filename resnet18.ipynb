{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸识别比赛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集\n",
    "\n",
    "1、上传zip格式压缩的数据集压缩包\n",
    "\n",
    "2、运行`! unzip dataset.zip`\n",
    "\n",
    "3、按上面的方法上传test.zip\n",
    "\n",
    "4、将数据集放置在根目录下，与work目录同级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import time\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "# import d2lzh_pytorch as d2l\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_face(batch_size):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "       # torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.Resize([330,330]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    train_imgs = torchvision.datasets.ImageFolder('./dataset/train', transform=transform)\n",
    "    test_imgs = torchvision.datasets.ImageFolder('./dataset/test', transform=transform)\n",
    "    train_iter = torch.utils.data.DataLoader(train_imgs, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(test_imgs, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_face(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取并保存人名和索引的对应关系，用于测试过程中将索引映射为人名\n",
    "import pickle\n",
    "# transform = torchvision.transforms.Compose([\n",
    "#     #torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "#     # torchvision.transforms.Resize([224, 224]),\n",
    "#     torchvision.transforms.ToTensor()\n",
    "# ])\n",
    "transform = torchvision.transforms.Compose([\n",
    "       # tosrchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.Resize([320,320]),\n",
    "        torchvision.transforms.CenterCrop([224, 224]),\n",
    "        \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "test_imgs = torchvision.datasets.ImageFolder('dataset/test', transform=transform)\n",
    "label = test_imgs.class_to_idx\n",
    "label = {value:key for key, value in label.items()}\n",
    "# print(len(label))\n",
    "# 写入文件\n",
    "label_hal = open('label.pkl', 'wb')\n",
    "s = pickle.dumps(label)\n",
    "label_hal.write(s)\n",
    "label_hal.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=models.resnet18(pretrained=True)\n",
    "# net.fc = torch.nn.Linear(512, len(label))\n",
    "net.fc = nn.Sequential(\n",
    "                        nn.ReLU(),                    \n",
    "                        nn.Dropout(0.6),\n",
    "                        nn.Linear(512, len(label))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        train_acc_list.append(train_acc_sum / n)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda:1\n",
      "epoch 1, loss 4.9271, train acc 0.166, test acc 0.269, time 22.5 sec\n",
      "epoch 2, loss 3.5061, train acc 0.357, test acc 0.389, time 23.8 sec\n",
      "epoch 3, loss 2.5857, train acc 0.485, test acc 0.517, time 24.8 sec\n",
      "epoch 4, loss 1.9244, train acc 0.594, test acc 0.573, time 24.2 sec\n",
      "epoch 5, loss 1.4685, train acc 0.684, test acc 0.672, time 24.8 sec\n",
      "epoch 6, loss 1.0958, train acc 0.757, test acc 0.731, time 21.5 sec\n",
      "epoch 7, loss 0.8677, train acc 0.806, test acc 0.743, time 23.8 sec\n",
      "epoch 8, loss 0.6299, train acc 0.869, test acc 0.796, time 23.2 sec\n",
      "epoch 9, loss 0.5058, train acc 0.897, test acc 0.804, time 24.4 sec\n",
      "epoch 10, loss 0.3785, train acc 0.928, test acc 0.821, time 24.3 sec\n",
      "epoch 11, loss 0.2895, train acc 0.952, test acc 0.815, time 22.3 sec\n",
      "epoch 12, loss 0.2305, train acc 0.965, test acc 0.856, time 25.2 sec\n",
      "epoch 13, loss 0.1841, train acc 0.976, test acc 0.850, time 22.2 sec\n",
      "epoch 14, loss 0.1469, train acc 0.980, test acc 0.855, time 24.4 sec\n",
      "epoch 15, loss 0.1325, train acc 0.983, test acc 0.854, time 24.5 sec\n",
      "epoch 16, loss 0.1054, train acc 0.991, test acc 0.877, time 23.5 sec\n",
      "epoch 17, loss 0.0955, train acc 0.989, test acc 0.868, time 24.7 sec\n",
      "epoch 18, loss 0.0695, train acc 0.996, test acc 0.873, time 24.6 sec\n",
      "epoch 19, loss 0.0611, train acc 0.995, test acc 0.878, time 25.4 sec\n",
      "epoch 20, loss 0.0526, train acc 0.996, test acc 0.881, time 23.9 sec\n",
      "epoch 21, loss 0.0469, train acc 0.997, test acc 0.885, time 23.7 sec\n",
      "epoch 22, loss 0.0489, train acc 0.998, test acc 0.884, time 25.5 sec\n",
      "epoch 23, loss 0.0512, train acc 0.995, test acc 0.884, time 23.7 sec\n",
      "epoch 24, loss 0.0455, train acc 0.997, test acc 0.876, time 25.1 sec\n",
      "epoch 25, loss 0.0379, train acc 0.998, test acc 0.885, time 25.3 sec\n",
      "epoch 26, loss 0.0350, train acc 0.999, test acc 0.887, time 25.1 sec\n",
      "epoch 27, loss 0.0315, train acc 0.999, test acc 0.895, time 24.2 sec\n",
      "epoch 28, loss 0.0371, train acc 0.998, test acc 0.888, time 24.6 sec\n",
      "epoch 29, loss 0.0389, train acc 0.998, test acc 0.884, time 24.1 sec\n",
      "epoch 30, loss 0.0314, train acc 0.998, test acc 0.888, time 25.6 sec\n",
      "epoch 31, loss 0.0264, train acc 0.999, test acc 0.894, time 24.1 sec\n",
      "epoch 32, loss 0.0311, train acc 0.999, test acc 0.890, time 25.0 sec\n",
      "epoch 33, loss 0.0352, train acc 0.998, test acc 0.886, time 24.2 sec\n",
      "epoch 34, loss 0.0352, train acc 0.998, test acc 0.879, time 22.8 sec\n",
      "epoch 35, loss 0.0320, train acc 1.000, test acc 0.886, time 25.5 sec\n",
      "epoch 36, loss 0.0478, train acc 0.996, test acc 0.878, time 23.0 sec\n",
      "epoch 37, loss 0.0280, train acc 0.999, test acc 0.882, time 23.5 sec\n",
      "epoch 38, loss 0.0215, train acc 0.999, test acc 0.891, time 22.3 sec\n",
      "epoch 39, loss 0.0231, train acc 0.999, test acc 0.891, time 22.8 sec\n",
      "epoch 40, loss 0.0182, train acc 0.999, test acc 0.885, time 23.8 sec\n",
      "epoch 41, loss 0.0200, train acc 0.999, test acc 0.894, time 21.5 sec\n",
      "epoch 42, loss 0.0278, train acc 0.998, test acc 0.893, time 23.6 sec\n",
      "epoch 43, loss 0.0215, train acc 0.999, test acc 0.898, time 23.2 sec\n",
      "epoch 44, loss 0.0194, train acc 1.000, test acc 0.893, time 24.1 sec\n",
      "epoch 45, loss 0.0168, train acc 1.000, test acc 0.894, time 22.7 sec\n",
      "epoch 46, loss 0.0170, train acc 0.999, test acc 0.895, time 23.7 sec\n",
      "epoch 47, loss 0.0151, train acc 1.000, test acc 0.894, time 24.1 sec\n",
      "epoch 48, loss 0.0153, train acc 1.000, test acc 0.893, time 25.1 sec\n",
      "epoch 49, loss 0.0182, train acc 0.999, test acc 0.893, time 24.2 sec\n",
      "epoch 50, loss 0.0147, train acc 0.999, test acc 0.897, time 26.0 sec\n",
      "epoch 51, loss 0.0139, train acc 0.999, test acc 0.898, time 24.6 sec\n",
      "epoch 52, loss 0.0139, train acc 0.999, test acc 0.894, time 24.4 sec\n",
      "epoch 53, loss 0.0137, train acc 1.000, test acc 0.895, time 24.5 sec\n",
      "epoch 54, loss 0.0128, train acc 1.000, test acc 0.894, time 22.3 sec\n",
      "epoch 55, loss 0.0106, train acc 1.000, test acc 0.899, time 24.8 sec\n",
      "epoch 56, loss 0.0138, train acc 0.999, test acc 0.892, time 22.0 sec\n",
      "epoch 57, loss 0.0157, train acc 0.999, test acc 0.891, time 23.8 sec\n",
      "epoch 58, loss 0.0149, train acc 1.000, test acc 0.895, time 23.9 sec\n",
      "epoch 59, loss 0.0179, train acc 1.000, test acc 0.894, time 19.6 sec\n",
      "epoch 60, loss 0.0129, train acc 1.000, test acc 0.880, time 18.4 sec\n",
      "epoch 61, loss 0.0128, train acc 0.999, test acc 0.886, time 16.7 sec\n",
      "epoch 62, loss 0.0132, train acc 0.999, test acc 0.890, time 13.3 sec\n",
      "epoch 63, loss 0.0129, train acc 1.000, test acc 0.893, time 12.9 sec\n",
      "epoch 64, loss 0.0112, train acc 1.000, test acc 0.894, time 13.8 sec\n",
      "epoch 65, loss 0.0118, train acc 0.999, test acc 0.892, time 17.7 sec\n",
      "epoch 66, loss 0.0111, train acc 1.000, test acc 0.891, time 16.7 sec\n",
      "epoch 67, loss 0.0095, train acc 1.000, test acc 0.902, time 18.2 sec\n",
      "epoch 68, loss 0.0095, train acc 1.000, test acc 0.895, time 19.0 sec\n",
      "epoch 69, loss 0.0091, train acc 1.000, test acc 0.898, time 18.2 sec\n",
      "epoch 70, loss 0.0093, train acc 1.000, test acc 0.892, time 19.9 sec\n",
      "epoch 71, loss 0.0149, train acc 1.000, test acc 0.889, time 19.4 sec\n",
      "epoch 72, loss 0.0107, train acc 1.000, test acc 0.891, time 18.8 sec\n",
      "epoch 73, loss 0.0114, train acc 1.000, test acc 0.894, time 19.9 sec\n",
      "epoch 74, loss 0.0105, train acc 1.000, test acc 0.896, time 19.5 sec\n",
      "epoch 75, loss 0.0104, train acc 1.000, test acc 0.893, time 18.6 sec\n",
      "epoch 76, loss 0.0103, train acc 1.000, test acc 0.888, time 19.8 sec\n",
      "epoch 77, loss 0.0087, train acc 1.000, test acc 0.895, time 18.6 sec\n",
      "epoch 78, loss 0.0092, train acc 1.000, test acc 0.891, time 20.3 sec\n",
      "epoch 79, loss 0.0100, train acc 1.000, test acc 0.895, time 18.0 sec\n",
      "epoch 80, loss 0.0086, train acc 1.000, test acc 0.894, time 19.6 sec\n",
      "epoch 81, loss 0.0099, train acc 1.000, test acc 0.890, time 19.4 sec\n",
      "epoch 82, loss 0.0090, train acc 1.000, test acc 0.898, time 18.6 sec\n",
      "epoch 83, loss 0.0101, train acc 1.000, test acc 0.898, time 18.9 sec\n",
      "epoch 84, loss 0.0092, train acc 1.000, test acc 0.889, time 19.3 sec\n",
      "epoch 85, loss 0.0090, train acc 1.000, test acc 0.895, time 17.3 sec\n",
      "epoch 86, loss 0.0090, train acc 1.000, test acc 0.897, time 18.7 sec\n",
      "epoch 87, loss 0.0085, train acc 1.000, test acc 0.894, time 17.4 sec\n",
      "epoch 88, loss 0.0088, train acc 0.999, test acc 0.899, time 18.2 sec\n",
      "epoch 89, loss 0.0102, train acc 1.000, test acc 0.901, time 17.3 sec\n",
      "epoch 90, loss 0.0101, train acc 1.000, test acc 0.894, time 16.4 sec\n",
      "epoch 91, loss 0.0097, train acc 1.000, test acc 0.895, time 17.9 sec\n",
      "epoch 92, loss 0.0098, train acc 1.000, test acc 0.902, time 18.2 sec\n",
      "epoch 93, loss 0.0101, train acc 1.000, test acc 0.901, time 16.1 sec\n",
      "epoch 94, loss 0.0097, train acc 1.000, test acc 0.897, time 17.9 sec\n",
      "epoch 95, loss 0.0110, train acc 0.999, test acc 0.898, time 16.6 sec\n",
      "epoch 96, loss 0.0095, train acc 1.000, test acc 0.894, time 16.7 sec\n",
      "epoch 97, loss 0.0092, train acc 1.000, test acc 0.895, time 19.3 sec\n",
      "epoch 98, loss 0.0101, train acc 1.000, test acc 0.901, time 17.6 sec\n",
      "epoch 99, loss 0.0079, train acc 1.000, test acc 0.898, time 19.2 sec\n",
      "epoch 100, loss 0.0085, train acc 1.000, test acc 0.891, time 19.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.005, 100\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=3e-4)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc = nn.Sequential(\n",
    "                        nn.ReLU(),                    \n",
    "                        nn.Dropout(0.65),\n",
    "                        nn.Linear(512, len(label))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda:1\n",
      "epoch 1, loss 5.0553, train acc 0.165, test acc 0.265, time 24.2 sec\n",
      "epoch 2, loss 4.0162, train acc 0.300, test acc 0.338, time 22.6 sec\n",
      "epoch 3, loss 3.5938, train acc 0.363, test acc 0.387, time 24.7 sec\n",
      "epoch 4, loss 3.2881, train acc 0.406, test acc 0.420, time 23.5 sec\n",
      "epoch 5, loss 3.0373, train acc 0.448, test acc 0.453, time 21.7 sec\n",
      "epoch 6, loss 2.8494, train acc 0.479, test acc 0.479, time 23.9 sec\n",
      "epoch 7, loss 2.7198, train acc 0.502, test acc 0.499, time 23.6 sec\n",
      "epoch 8, loss 2.5445, train acc 0.522, test acc 0.517, time 24.2 sec\n",
      "epoch 9, loss 2.4351, train acc 0.545, test acc 0.532, time 23.9 sec\n",
      "epoch 10, loss 2.3054, train acc 0.561, test acc 0.548, time 22.6 sec\n",
      "epoch 11, loss 2.2173, train acc 0.576, test acc 0.558, time 23.7 sec\n",
      "epoch 12, loss 2.0880, train acc 0.601, test acc 0.574, time 24.0 sec\n",
      "epoch 13, loss 2.0253, train acc 0.611, test acc 0.577, time 22.3 sec\n",
      "epoch 14, loss 1.9229, train acc 0.629, test acc 0.600, time 24.7 sec\n",
      "epoch 15, loss 1.8467, train acc 0.642, test acc 0.611, time 21.4 sec\n",
      "epoch 16, loss 1.7945, train acc 0.655, test acc 0.618, time 24.4 sec\n",
      "epoch 17, loss 1.6861, train acc 0.670, test acc 0.628, time 19.6 sec\n",
      "epoch 18, loss 1.6329, train acc 0.684, test acc 0.633, time 23.7 sec\n",
      "epoch 19, loss 1.5451, train acc 0.702, test acc 0.644, time 23.3 sec\n",
      "epoch 20, loss 1.4988, train acc 0.710, test acc 0.656, time 22.9 sec\n",
      "epoch 21, loss 1.3999, train acc 0.727, test acc 0.665, time 26.6 sec\n",
      "epoch 22, loss 1.3787, train acc 0.735, test acc 0.676, time 29.0 sec\n",
      "epoch 23, loss 1.3161, train acc 0.750, test acc 0.683, time 28.5 sec\n",
      "epoch 24, loss 1.2475, train acc 0.761, test acc 0.699, time 27.2 sec\n",
      "epoch 25, loss 1.1974, train acc 0.769, test acc 0.692, time 30.4 sec\n",
      "epoch 26, loss 1.1336, train acc 0.780, test acc 0.704, time 25.7 sec\n",
      "epoch 27, loss 1.0933, train acc 0.795, test acc 0.712, time 23.3 sec\n",
      "epoch 28, loss 1.0353, train acc 0.805, test acc 0.718, time 24.5 sec\n",
      "epoch 29, loss 0.9967, train acc 0.811, test acc 0.722, time 20.1 sec\n",
      "epoch 30, loss 0.9647, train acc 0.822, test acc 0.731, time 24.0 sec\n",
      "epoch 31, loss 0.9152, train acc 0.830, test acc 0.732, time 23.4 sec\n",
      "epoch 32, loss 0.8863, train acc 0.844, test acc 0.744, time 28.5 sec\n",
      "epoch 33, loss 0.8390, train acc 0.851, test acc 0.739, time 27.9 sec\n",
      "epoch 34, loss 0.8024, train acc 0.857, test acc 0.747, time 27.4 sec\n",
      "epoch 35, loss 0.7665, train acc 0.867, test acc 0.761, time 28.8 sec\n",
      "epoch 36, loss 0.7399, train acc 0.876, test acc 0.768, time 23.9 sec\n",
      "epoch 37, loss 0.7030, train acc 0.882, test acc 0.765, time 23.3 sec\n",
      "epoch 38, loss 0.6747, train acc 0.890, test acc 0.776, time 23.1 sec\n",
      "epoch 39, loss 0.6569, train acc 0.893, test acc 0.788, time 23.8 sec\n",
      "epoch 40, loss 0.6284, train acc 0.899, test acc 0.794, time 24.6 sec\n",
      "epoch 41, loss 0.5935, train acc 0.907, test acc 0.799, time 21.7 sec\n",
      "epoch 42, loss 0.5622, train acc 0.914, test acc 0.800, time 23.8 sec\n",
      "epoch 43, loss 0.5380, train acc 0.917, test acc 0.800, time 21.9 sec\n",
      "epoch 44, loss 0.5084, train acc 0.928, test acc 0.804, time 23.3 sec\n",
      "epoch 45, loss 0.4970, train acc 0.928, test acc 0.818, time 23.0 sec\n",
      "epoch 46, loss 0.4822, train acc 0.926, test acc 0.811, time 22.0 sec\n",
      "epoch 47, loss 0.4512, train acc 0.940, test acc 0.810, time 23.7 sec\n",
      "epoch 48, loss 0.4331, train acc 0.941, test acc 0.819, time 22.5 sec\n",
      "epoch 49, loss 0.3983, train acc 0.954, test acc 0.816, time 23.1 sec\n",
      "epoch 50, loss 0.3873, train acc 0.954, test acc 0.818, time 22.7 sec\n",
      "epoch 51, loss 0.3863, train acc 0.954, test acc 0.830, time 22.4 sec\n",
      "epoch 52, loss 0.3624, train acc 0.959, test acc 0.829, time 22.7 sec\n",
      "epoch 53, loss 0.3504, train acc 0.963, test acc 0.836, time 23.6 sec\n",
      "epoch 54, loss 0.3398, train acc 0.964, test acc 0.832, time 19.4 sec\n",
      "epoch 55, loss 0.3355, train acc 0.961, test acc 0.831, time 17.4 sec\n",
      "epoch 56, loss 0.3213, train acc 0.964, test acc 0.836, time 18.6 sec\n",
      "epoch 57, loss 0.2981, train acc 0.969, test acc 0.828, time 16.7 sec\n",
      "epoch 58, loss 0.2872, train acc 0.974, test acc 0.832, time 17.4 sec\n",
      "epoch 59, loss 0.2727, train acc 0.973, test acc 0.834, time 16.1 sec\n",
      "epoch 60, loss 0.2708, train acc 0.971, test acc 0.838, time 17.8 sec\n",
      "epoch 61, loss 0.2434, train acc 0.979, test acc 0.846, time 17.2 sec\n",
      "epoch 62, loss 0.2428, train acc 0.977, test acc 0.837, time 18.0 sec\n",
      "epoch 63, loss 0.2371, train acc 0.980, test acc 0.839, time 18.8 sec\n",
      "epoch 64, loss 0.2267, train acc 0.981, test acc 0.841, time 16.7 sec\n",
      "epoch 65, loss 0.2167, train acc 0.983, test acc 0.849, time 18.2 sec\n",
      "epoch 66, loss 0.2178, train acc 0.984, test acc 0.847, time 17.2 sec\n",
      "epoch 67, loss 0.2074, train acc 0.985, test acc 0.845, time 18.4 sec\n",
      "epoch 68, loss 0.1958, train acc 0.988, test acc 0.849, time 17.5 sec\n",
      "epoch 69, loss 0.2007, train acc 0.983, test acc 0.846, time 18.0 sec\n",
      "epoch 70, loss 0.1877, train acc 0.988, test acc 0.841, time 18.1 sec\n",
      "epoch 71, loss 0.1684, train acc 0.990, test acc 0.842, time 18.0 sec\n",
      "epoch 72, loss 0.1709, train acc 0.990, test acc 0.849, time 18.4 sec\n",
      "epoch 73, loss 0.1679, train acc 0.988, test acc 0.855, time 17.7 sec\n",
      "epoch 74, loss 0.1612, train acc 0.990, test acc 0.845, time 18.7 sec\n",
      "epoch 75, loss 0.1664, train acc 0.990, test acc 0.848, time 16.5 sec\n",
      "epoch 76, loss 0.1511, train acc 0.989, test acc 0.856, time 18.2 sec\n",
      "epoch 77, loss 0.1395, train acc 0.994, test acc 0.854, time 16.6 sec\n",
      "epoch 78, loss 0.1342, train acc 0.995, test acc 0.850, time 18.3 sec\n",
      "epoch 79, loss 0.1465, train acc 0.992, test acc 0.859, time 16.5 sec\n",
      "epoch 80, loss 0.1350, train acc 0.994, test acc 0.855, time 17.7 sec\n",
      "epoch 81, loss 0.1357, train acc 0.991, test acc 0.849, time 17.6 sec\n",
      "epoch 82, loss 0.1330, train acc 0.990, test acc 0.850, time 17.0 sec\n",
      "epoch 83, loss 0.1242, train acc 0.995, test acc 0.854, time 18.0 sec\n",
      "epoch 84, loss 0.1242, train acc 0.995, test acc 0.858, time 16.8 sec\n",
      "epoch 85, loss 0.1245, train acc 0.995, test acc 0.852, time 18.0 sec\n",
      "epoch 86, loss 0.1164, train acc 0.993, test acc 0.853, time 16.3 sec\n",
      "epoch 87, loss 0.1162, train acc 0.993, test acc 0.852, time 18.2 sec\n",
      "epoch 88, loss 0.1146, train acc 0.993, test acc 0.855, time 17.2 sec\n",
      "epoch 89, loss 0.1143, train acc 0.993, test acc 0.856, time 17.9 sec\n",
      "epoch 90, loss 0.1033, train acc 0.997, test acc 0.855, time 18.7 sec\n",
      "epoch 91, loss 0.1076, train acc 0.995, test acc 0.853, time 19.9 sec\n",
      "epoch 92, loss 0.1010, train acc 0.996, test acc 0.855, time 20.6 sec\n",
      "epoch 93, loss 0.0969, train acc 0.996, test acc 0.856, time 18.4 sec\n",
      "epoch 94, loss 0.0928, train acc 0.997, test acc 0.854, time 20.0 sec\n",
      "epoch 95, loss 0.0941, train acc 0.997, test acc 0.855, time 18.6 sec\n",
      "epoch 96, loss 0.0922, train acc 0.996, test acc 0.854, time 20.1 sec\n",
      "epoch 97, loss 0.0909, train acc 0.996, test acc 0.846, time 20.1 sec\n",
      "epoch 98, loss 0.0865, train acc 0.996, test acc 0.858, time 19.6 sec\n",
      "epoch 99, loss 0.0893, train acc 0.995, test acc 0.852, time 20.1 sec\n",
      "epoch 100, loss 0.0881, train acc 0.996, test acc 0.854, time 18.7 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.05, 100\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=1e-4)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 自己加个画图\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = np.arange(1, len(train_acc_list)+1, 1)\n",
    "y1 = np.array(train_acc_list)\n",
    "y2 = np.array(test_acc_list)\n",
    "plt.plot(x, y1, label=\"train\")\n",
    "plt.plot(x, y2, linestyle = \"--\", label=\"test\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title('train & test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.6)\n",
       "    (2): Linear(in_features=2048, out_features=311, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './resnet18.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成识别结果文件测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练好的模型\n",
    "model = torch.load('./resnet18.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取本次训练的人名和索引的对应关系\n",
    "label = {}\n",
    "with open('label.pkl','rb') as file:\n",
    "    label = pickle.loads(file.read())\n",
    "# print(label)\n",
    "# 测试集label对应关系\n",
    "import pickle\n",
    "label_answer = {}\n",
    "with open('label_answer.pkl','rb') as file:\n",
    "    label_answer = pickle.loads(file.read())\n",
    "label_answer = {value:key for key, value in label_answer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载测试数据（在test目录下）\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1), # 彩色图像转灰度图像num_output_channels默认1\n",
    "    torchvision.transforms.Resize([224, 224]),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "# 生成测试结果文件\n",
    "path = os.listdir('test')\n",
    "r_d = {}\n",
    "for f in path:\n",
    "    img = Image.open('test/' + f)\n",
    "    test_imgs = transform(img).unsqueeze(0)\n",
    "    test_imgs = test_imgs.to(device)\n",
    "    y = model(test_imgs)\n",
    "    pred = torch.argmax(y, dim = 1)\n",
    "    r = label_answer[label[int(pred)]]\n",
    "    r_d[int(f.strip('.jpg'))] = r\n",
    "\n",
    "# 写入结果文件\n",
    "r_d = sorted(r_d.items(), key=lambda a:a[0])\n",
    "r_d = dict(r_d)\n",
    "ret = open(\"result.csv\",\"w\")\n",
    "for key, value in r_d.items():\n",
    "    print(\"%d,%s\"%(key, value), file=ret)\n",
    "ret.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "0.2.1\n",
      "cpu\n",
      "3578.jpg\n",
      "5109.jpg\n",
      "1409.jpg\n",
      "2896.jpg\n",
      "3550.jpg\n",
      "2869.jpg\n",
      "2855.jpg\n",
      "1384.jpg\n",
      "1810.jpg\n",
      "3791.jpg\n",
      "3168.jpg\n",
      "3154.jpg\n",
      "3626.jpg\n",
      "1970.jpg\n",
      "2289.jpg\n",
      "5294.jpg\n",
      "4834.jpg\n",
      "1794.jpg\n",
      "1582.jpg\n",
      "4388.jpg\n",
      "5097.jpg\n",
      "2920.jpg\n",
      "1540.jpg\n",
      "4410.jpg\n",
      "1781.jpg\n",
      "1971.jpg\n",
      "229.jpg\n",
      "375.jpg\n",
      "407.jpg\n",
      "3753.jpg\n",
      "3035.jpg\n",
      "1178.jpg\n",
      "1420.jpg\n",
      "2129.jpg\n",
      "3551.jpg\n",
      "2103.jpg\n",
      "2665.jpg\n",
      "1422.jpg\n",
      "2467.jpg\n",
      "1608.jpg\n",
      "2507.jpg\n",
      "4604.jpg\n",
      "1026.jpg\n",
      "5240.jpg\n",
      "203.jpg\n",
      "4823.jpg\n",
      "2739.jpg\n",
      "3427.jpg\n",
      "5095.jpg\n",
      "1595.jpg\n",
      "3382.jpg\n",
      "1580.jpg\n",
      "3803.jpg\n",
      "2274.jpg\n",
      "2506.jpg\n",
      "1153.jpg\n",
      "2466.jpg\n",
      "2314.jpg\n",
      "2472.jpg\n",
      "3591.jpg\n",
      "1351.jpg\n",
      "5137.jpg\n",
      "3546.jpg\n",
      "4567.jpg\n",
      "3224.jpg\n",
      "170.jpg\n",
      "3754.jpg\n",
      "4749.jpg\n",
      "5319.jpg\n",
      "3797.jpg\n",
      "2270.jpg\n",
      "5286.jpg\n",
      "3807.jpg\n",
      "1976.jpg\n",
      "548.jpg\n",
      "5053.jpg\n",
      "2066.jpg\n",
      "4833.jpg\n",
      "2339.jpg\n",
      "4748.jpg\n",
      "4984.jpg\n",
      "1624.jpg\n",
      "2846.jpg\n",
      "4576.jpg\n",
      "3543.jpg\n",
      "2887.jpg\n",
      "826.jpg\n",
      "2663.jpg\n",
      "3569.jpg\n",
      "5332.jpg\n",
      "4038.jpg\n",
      "1140.jpg\n",
      "2475.jpg\n",
      "3780.jpg\n",
      "1183.jpg\n",
      "588.jpg\n",
      "577.jpg\n",
      "2298.jpg\n",
      "5291.jpg\n",
      "3804.jpg\n",
      "2071.jpg\n",
      "946.jpg\n",
      "1587.jpg\n",
      "1592.jpg\n",
      "4367.jpg\n",
      "953.jpg\n",
      "1551.jpg\n",
      "1545.jpg\n",
      "3434.jpg\n",
      "5284.jpg\n",
      "210.jpg\n",
      "1035.jpg\n",
      "3636.jpg\n",
      "416.jpg\n",
      "364.jpg\n",
      "2306.jpg\n",
      "2448.jpg\n",
      "600.jpg\n",
      "2662.jpg\n",
      "5131.jpg\n",
      "2611.jpg\n",
      "3527.jpg\n",
      "883.jpg\n",
      "3296.jpg\n",
      "3719.jpg\n",
      "2349.jpg\n",
      "5383.jpg\n",
      "4664.jpg\n",
      "4843.jpg\n",
      "2598.jpg\n",
      "2942.jpg\n",
      "712.jpg\n",
      "1286.jpg\n",
      "5037.jpg\n",
      "4473.jpg\n",
      "3308.jpg\n",
      "1084.jpg\n",
      "510.jpg\n",
      "5235.jpg\n",
      "5209.jpg\n",
      "289.jpg\n",
      "4705.jpg\n",
      "2823.jpg\n",
      "4249.jpg\n",
      "2610.jpg\n",
      "2176.jpg\n",
      "17.jpg\n",
      "4263.jpg\n",
      "2612.jpg\n",
      "2835.jpg\n",
      "102.jpg\n",
      "4707.jpg\n",
      "4075.jpg\n",
      "3040.jpg\n",
      "328.jpg\n",
      "2389.jpg\n",
      "4673.jpg\n",
      "3685.jpg\n",
      "506.jpg\n",
      "4840.jpg\n",
      "512.jpg\n",
      "2982.jpg\n",
      "1521.jpg\n",
      "2969.jpg\n",
      "1284.jpg\n",
      "1087.jpg\n",
      "507.jpg\n",
      "4128.jpg\n",
      "4100.jpg\n",
      "5381.jpg\n",
      "3914.jpg\n",
      "4048.jpg\n",
      "3727.jpg\n",
      "3294.jpg\n",
      "842.jpg\n",
      "5168.jpg\n",
      "2161.jpg\n",
      "2159.jpg\n",
      "1336.jpg\n",
      "846.jpg\n",
      "891.jpg\n",
      "885.jpg\n",
      "5352.jpg\n",
      "2401.jpg\n",
      "5408.jpg\n",
      "477.jpg\n",
      "3910.jpg\n",
      "3904.jpg\n",
      "5226.jpg\n",
      "4110.jpg\n",
      "265.jpg\n",
      "1929.jpg\n",
      "4851.jpg\n",
      "4879.jpg\n",
      "2993.jpg\n",
      "3483.jpg\n",
      "5019.jpg\n",
      "3440.jpg\n",
      "4111.jpg\n",
      "2548.jpg\n",
      "5233.jpg\n",
      "1690.jpg\n",
      "4930.jpg\n",
      "5409.jpg\n",
      "4703.jpg\n",
      "5151.jpg\n",
      "3520.jpg\n",
      "5145.jpg\n",
      "3536.jpg\n",
      "2600.jpg\n",
      "845.jpg\n",
      "851.jpg\n",
      "104.jpg\n",
      "2833.jpg\n",
      "1645.jpg\n",
      "5379.jpg\n",
      "4067.jpg\n",
      "5392.jpg\n",
      "4098.jpg\n",
      "312.jpg\n",
      "3091.jpg\n",
      "1876.jpg\n",
      "4885.jpg\n",
      "1057.jpg\n",
      "5231.jpg\n",
      "272.jpg\n",
      "4852.jpg\n",
      "1902.jpg\n",
      "5033.jpg\n",
      "931.jpg\n",
      "4477.jpg\n",
      "1269.jpg\n",
      "3494.jpg\n",
      "2952.jpg\n",
      "2985.jpg\n",
      "3872.jpg\n",
      "1730.jpg\n",
      "3090.jpg\n",
      "2417.jpg\n",
      "2615.jpg\n",
      "5152.jpg\n",
      "1334.jpg\n",
      "4255.jpg\n",
      "2624.jpg\n",
      "4296.jpg\n",
      "2803.jpg\n",
      "4057.jpg\n",
      "4731.jpg\n",
      "4725.jpg\n",
      "2368.jpg\n",
      "2383.jpg\n",
      "3894.jpg\n",
      "4645.jpg\n",
      "1715.jpg\n",
      "3843.jpg\n",
      "530.jpg\n",
      "2036.jpg\n",
      "2778.jpg\n",
      "4484.jpg\n",
      "3301.jpg\n",
      "1502.jpg\n",
      "928.jpg\n",
      "2745.jpg\n",
      "2751.jpg\n",
      "3665.jpg\n",
      "3936.jpg\n",
      "1106.jpg\n",
      "3705.jpg\n",
      "3063.jpg\n",
      "4724.jpg\n",
      "5162.jpg\n",
      "848.jpg\n",
      "684.jpg\n",
      "2625.jpg\n",
      "4254.jpg\n",
      "20.jpg\n",
      "4518.jpg\n",
      "5160.jpg\n",
      "5174.jpg\n",
      "4726.jpg\n",
      "1689.jpg\n",
      "321.jpg\n",
      "1070.jpg\n",
      "3459.jpg\n",
      "3303.jpg\n",
      "1500.jpg\n",
      "1267.jpg\n",
      "3316.jpg\n",
      "5029.jpg\n",
      "268.jpg\n",
      "2578.jpg\n",
      "283.jpg\n",
      "4647.jpg\n",
      "3882.jpg\n",
      "3706.jpg\n",
      "4055.jpg\n",
      "2356.jpg\n",
      "2183.jpg\n",
      "5161.jpg\n",
      "2632.jpg\n",
      "1465.jpg\n",
      "3266.jpg\n",
      "3528.jpg\n",
      "4521.jpg\n",
      "2144.jpg\n",
      "27.jpg\n",
      "2805.jpg\n",
      "5373.jpg\n",
      "2434.jpg\n",
      "3104.jpg\n",
      "1075.jpg\n",
      "3676.jpg\n",
      "4119.jpg\n",
      "2554.jpg\n",
      "1908.jpg\n",
      "250.jpg\n",
      "735.jpg\n",
      "4454.jpg\n",
      "3313.jpg\n",
      "5010.jpg\n",
      "1510.jpg\n",
      "3307.jpg\n",
      "3844.jpg\n",
      "537.jpg\n",
      "4118.jpg\n",
      "1706.jpg\n",
      "1712.jpg\n",
      "1869.jpg\n",
      "3059.jpg\n",
      "5372.jpg\n",
      "494.jpg\n",
      "2838.jpg\n",
      "2810.jpg\n",
      "5158.jpg\n",
      "682.jpg\n",
      "3503.jpg\n",
      "1314.jpg\n",
      "3259.jpg\n",
      "125.jpg\n",
      "5416.jpg\n",
      "5358.jpg\n",
      "3729.jpg\n",
      "327.jpg\n",
      "2386.jpg\n",
      "3649.jpg\n",
      "4132.jpg\n",
      "3885.jpg\n",
      "509.jpg\n",
      "2033.jpg\n",
      "2967.jpg\n",
      "5013.jpg\n",
      "4319.jpg\n",
      "4872.jpg\n",
      "252.jpg\n",
      "2542.jpg\n",
      "4669.jpg\n",
      "3927.jpg\n",
      "454.jpg\n",
      "440.jpg\n",
      "3728.jpg\n",
      "1881.jpg\n",
      "4721.jpg\n",
      "5198.jpg\n",
      "2813.jpg\n",
      "816.jpg\n",
      "3217.jpg\n",
      "95.jpg\n",
      "157.jpg\n",
      "5316.jpg\n",
      "3767.jpg\n",
      "2519.jpg\n",
      "5276.jpg\n",
      "3834.jpg\n",
      "4829.jpg\n",
      "2733.jpg\n",
      "1560.jpg\n",
      "2901.jpg\n",
      "2915.jpg\n",
      "787.jpg\n",
      "3404.jpg\n",
      "2040.jpg\n",
      "3438.jpg\n",
      "4343.jpg\n",
      "2732.jpg\n",
      "546.jpg\n",
      "4828.jpg\n",
      "432.jpg\n",
      "1818.jpg\n",
      "3941.jpg\n",
      "3799.jpg\n",
      "3772.jpg\n",
      "1617.jpg\n",
      "4021.jpg\n",
      "3982.jpg\n",
      "4592.jpg\n",
      "3216.jpg\n",
      "195.jpg\n",
      "3202.jpg\n",
      "1429.jpg\n",
      "4221.jpg\n",
      "2650.jpg\n",
      "3214.jpg\n",
      "168.jpg\n",
      "4751.jpg\n",
      "5315.jpg\n",
      "3002.jpg\n",
      "4786.jpg\n",
      "1832.jpg\n",
      "4143.jpg\n",
      "1985.jpg\n",
      "587.jpg\n",
      "1952.jpg\n",
      "222.jpg\n",
      "236.jpg\n",
      "1577.jpg\n",
      "2080.jpg\n",
      "784.jpg\n",
      "2043.jpg\n",
      "4195.jpg\n",
      "2484.jpg\n",
      "4787.jpg\n",
      "3956.jpg\n",
      "5314.jpg\n",
      "394.jpg\n",
      "4585.jpg\n",
      "196.jpg\n",
      "810.jpg\n",
      "2899.jpg\n",
      "4230.jpg\n",
      "2682.jpg\n",
      "1162.jpg\n",
      "5310.jpg\n",
      "4998.jpg\n",
      "4754.jpg\n",
      "3985.jpg\n",
      "1189.jpg\n",
      "582.jpg\n",
      "3173.jpg\n",
      "2251.jpg\n",
      "4620.jpg\n",
      "3629.jpg\n",
      "1957.jpg\n",
      "4185.jpg\n",
      "1572.jpg\n",
      "780.jpg\n",
      "1200.jpg\n",
      "2721.jpg\n",
      "2912.jpg\n",
      "1599.jpg\n",
      "971.jpg\n",
      "3358.jpg\n",
      "2708.jpg\n",
      "3402.jpg\n",
      "540.jpg\n",
      "226.jpg\n",
      "4621.jpg\n",
      "2536.jpg\n",
      "2244.jpg\n",
      "1765.jpg\n",
      "4609.jpg\n",
      "4755.jpg\n",
      "3748.jpg\n",
      "1639.jpg\n",
      "3238.jpg\n",
      "4557.jpg\n",
      "3576.jpg\n",
      "4569.jpg\n",
      "3574.jpg\n",
      "191.jpg\n",
      "84.jpg\n",
      "4582.jpg\n",
      "4019.jpg\n",
      "4970.jpg\n",
      "1834.jpg\n",
      "4780.jpg\n",
      "1820.jpg\n",
      "1015.jpg\n",
      "556.jpg\n",
      "224.jpg\n",
      "4810.jpg\n",
      "1954.jpg\n",
      "4192.jpg\n",
      "2093.jpg\n",
      "768.jpg\n",
      "4346.jpg\n",
      "5058.jpg\n",
      "3830.jpg\n",
      "4636.jpg\n",
      "1982.jpg\n",
      "5266.jpg\n",
      "345.jpg\n",
      "4971.jpg\n",
      "2333.jpg\n",
      "1148.jpg\n",
      "3039.jpg\n",
      "147.jpg\n",
      "621.jpg\n",
      "2864.jpg\n",
      "46.jpg\n",
      "5104.jpg\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 根据生成识别文件的代码，自行编写main.py文件，要求文件可生成结果文件result.csv\n",
    "# 已知的坑：main.py中需增加模型类的定义\n",
    "\n",
    "# 测试main.py生成result.csv\n",
    "!python main.py\n",
    "# 生成后自行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
